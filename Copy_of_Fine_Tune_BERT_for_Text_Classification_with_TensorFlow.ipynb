{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iVibudh/Fine-tune-BERT-for-Text-Classification/blob/main/Copy_of_Fine_Tune_BERT_for_Text_Classification_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGCJYkQj_Uu2"
      },
      "source": [
        "<h2 align=center> Fine-Tune BERT for Text Classification with TensorFlow</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y2m1S6e12il"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1fnJTeJs5HUpz7nix-F9E6EZdgUflqyEu' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 1: BERT Classification Model</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYYYWqWr_WCC"
      },
      "source": [
        "In this [project](https://www.coursera.org/projects/fine-tune-bert-tensorflow/), you will learn how to fine-tune a BERT model for text classification using TensorFlow and TF-Hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yQG5PCO_WFx"
      },
      "source": [
        "The pretrained BERT model used in this project is [available](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2) on [TensorFlow Hub](https://tfhub.dev/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pKNS21u_WJo"
      },
      "source": [
        "### Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3NHSMXv_WMv"
      },
      "source": [
        "By the time you complete this project, you will be able to:\n",
        "\n",
        "- Build TensorFlow Input Pipelines for Text Data with the [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) API\n",
        "- Tokenize and Preprocess Text for BERT\n",
        "- Fine-tune BERT for text classification with TensorFlow 2 and [TF Hub](https://tfhub.dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6BEe-3-AVRQ"
      },
      "source": [
        "### Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc9f-8rLAVUS"
      },
      "source": [
        "In order to be successful with this project, it is assumed you are:\n",
        "\n",
        "- Competent in the Python programming language\n",
        "- Familiar with deep learning for Natural Language Processing (NLP)\n",
        "- Familiar with TensorFlow, and its Keras API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYXXV5n3Ab-4"
      },
      "source": [
        "### Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhK-SYGyAjxe"
      },
      "source": [
        "This project/notebook consists of several Tasks.\n",
        "\n",
        "- **[Task 1]()**: Introduction to the Project.\n",
        "- **[Task 2]()**: Setup your TensorFlow and Colab Runtime\n",
        "- **[Task 3]()**: Download and Import the Quora Insincere Questions Dataset\n",
        "- **[Task 4]()**: Create tf.data.Datasets for Training and Evaluation\n",
        "- **[Task 5]()**: Download a Pre-trained BERT Model from TensorFlow Hub\n",
        "- **[Task 6]()**: Tokenize and Preprocess Text for BERT\n",
        "- **[Task 7]()**: Wrap a Python Function into a TensorFlow op for Eager Execution\n",
        "- **[Task 8]()**: Create a TensorFlow Input Pipeline with `tf.data`\n",
        "- **[Task 9]()**: Add a Classification Head to the BERT `hub.KerasLayer`\n",
        "- **[Task 10]()**: Fine-Tune BERT for Text Classification\n",
        "- **[Task 11]()**: Evaluate the BERT Text Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaArqXjRAcBa"
      },
      "source": [
        "## Task 2: Setup your TensorFlow and Colab Runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDDhjzZ5A4Q_"
      },
      "source": [
        "You will only be able to use the Colab Notebook after you save it to your Google Drive folder. Click on the File menu and select “Save a copy in Drive…\n",
        "\n",
        "![Copy to Drive](https://drive.google.com/uc?id=1CH3eDmuJL8WR0AP1r3UE6sOPuqq8_Wl7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpe6GhLuBJWB"
      },
      "source": [
        "### Check GPU Availability\n",
        "\n",
        "Check if your Colab notebook is configured to use Graphical Processing Units (GPUs). If zero GPUs are available, check if the Colab notebook is configured to use GPUs (Menu > Runtime > Change Runtime Type).\n",
        "\n",
        "![Hardware Accelerator Settings](https://drive.google.com/uc?id=1qrihuuMtvzXJHiRV8M7RngbxFYipXKQx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V9c8vzSL3aj",
        "outputId": "65385aa2-e4b2-4baf-e821-ca94dbd407d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar  2 19:53:03 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neCUwizJGxWs"
      },
      "source": [
        "Ideally, we want to be assigned with \"Tesla P100\" or \"Tesla T4 GPUs\" with Kuda course. For better performance. \n",
        "\n",
        "If you were assigned the K80 then try to Factory restart the environment and check again.\n",
        "\n",
        "Runtime -> Factory Reset Runtime -> Running the cell !nvidia-smi\n",
        "\n",
        "\n",
        "If it is still giving you K80 then don't sweat, the code will still work in this notebook. The training will complete but might take a little longer. \n",
        "\n",
        "Also, if you load heavy models on your colab and the Facory reset, then there are more chances of you getting a better GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Obch3rAuBVf0"
      },
      "source": [
        "### Install TensorFlow and TensorFlow Model Garden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUQEY3dFB0jX",
        "outputId": "76397509-c85f-41a4-84fd-94a3adb28722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aU3YLZ1TYKUt"
      },
      "outputs": [],
      "source": [
        "# # Tensorflow already installed so No need to install tensorflow again. \n",
        "# !pip install -q tensorflow==2.3.0\n",
        "\n",
        "# # need to get 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFRTC-zwUy6D",
        "outputId": "9181ca0c-6fa9-4088-be73-e7976fa96026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Clone the official Tensorflow model garden repository from Github. \n",
        "!git clone --depth 1 -b v2.3.0 https://github.com/tensorflow/models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H2G0571zLLs",
        "outputId": "d44bc09d-9e32-4eca-bb9d-e8aa7c53666c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# install requirements to use tensorflow/models repository\n",
        "!pip install -Uqr models/official/requirements.txt\n",
        "# you may have to restart the runtime afterwards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24fSyqo_JwZx"
      },
      "source": [
        "If Building is done then you can ignore the errors. Most of these errors are about version compatibility, in our case this should work as these packages are forward compatible. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVjksk4yCXur"
      },
      "source": [
        "## Restart the Runtime\n",
        "\n",
        "**Note** \n",
        "After installing the required Python packages, you'll need to restart the Colab Runtime Engine (Menu > Runtime > Restart runtime...)\n",
        "\n",
        "![Restart of the Colab Runtime Engine](https://drive.google.com/uc?id=1xnjAy2sxIymKhydkqb0RKzgVK9rh3teH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMsEoT3Fg4Wg"
      },
      "source": [
        "## Task 3: Download and Import the Quora Insincere Questions Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmqEylyFYTdP",
        "outputId": "94410483-a9e4-4444-e372-9afd7147f1d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import sys\n",
        "sys.path.append('models')\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "from official.nlp import optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuX1lB8pPJ-W",
        "outputId": "6e100772-eb82-41a0-94bc-bd4ddf8f83a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF Version:  2.3.0\n",
            "Eager mode:  True\n",
            "Hub version:  0.12.0\n",
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtbwpWgyEZg7"
      },
      "source": [
        "A downloadable copy of the [Quora Insincere Questions Classification data](https://www.kaggle.com/c/quora-insincere-questions-classification/data) can be found [https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip](https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip). Decompress and read the data into a pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nI-9itVwCCQ",
        "outputId": "cc1c845a-5526-417b-ee03-d5befb7ba8cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1306122, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip',\n",
        "                 compression = 'zip',\n",
        "                 low_memory = False)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "yeHE98KiMvDd",
        "outputId": "b78fdfe5-b350-4717-fd66-7e4f19de3318"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-48170f87-d48b-4131-b458-4efba63010e9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1306102</th>\n",
              "      <td>ffff3778790af9baae76</td>\n",
              "      <td>What steps can I take to live a normal life if...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306103</th>\n",
              "      <td>ffff3f0a2449ffe4b9ff</td>\n",
              "      <td>Isn't Trump right after all? Why should the US...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306104</th>\n",
              "      <td>ffff41393389d4206066</td>\n",
              "      <td>Is 33 too late for a career in creative advert...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306105</th>\n",
              "      <td>ffff42493fc203cd9532</td>\n",
              "      <td>What is difference between the filteration wor...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306106</th>\n",
              "      <td>ffff48dd47bee89fff79</td>\n",
              "      <td>If the universe \"popped\" into existence from n...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306107</th>\n",
              "      <td>ffff5fd051a032f32a39</td>\n",
              "      <td>How does a shared service technology team meas...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306108</th>\n",
              "      <td>ffff6d528040d3888b93</td>\n",
              "      <td>How is DSATM civil engineering?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306109</th>\n",
              "      <td>ffff8776cd30cdc8d7f8</td>\n",
              "      <td>Do you know any problem that depends solely on...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306110</th>\n",
              "      <td>ffff94d427ade3716cd1</td>\n",
              "      <td>What are some comic ideas for you Tube videos ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306111</th>\n",
              "      <td>ffffa382c58368071dc9</td>\n",
              "      <td>If you had $10 million of Bitcoin, could you s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306112</th>\n",
              "      <td>ffffa5b0fa76431c063f</td>\n",
              "      <td>Are you ashamed of being an Indian?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306113</th>\n",
              "      <td>ffffae5dbda3dc9e9771</td>\n",
              "      <td>What are the methods to determine fossil ages ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306114</th>\n",
              "      <td>ffffba7c4888798571c1</td>\n",
              "      <td>What is your story today?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306115</th>\n",
              "      <td>ffffc0c7158658a06fd9</td>\n",
              "      <td>How do I consume 150 gms protein daily both ve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306116</th>\n",
              "      <td>ffffc404da586ac5a08f</td>\n",
              "      <td>What are the good career options for a msc che...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306117</th>\n",
              "      <td>ffffcc4e2331aaf1e41e</td>\n",
              "      <td>What other technical skills do you need as a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306118</th>\n",
              "      <td>ffffd431801e5a2f4861</td>\n",
              "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306119</th>\n",
              "      <td>ffffd48fb36b63db010c</td>\n",
              "      <td>Is foam insulation toxic?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306120</th>\n",
              "      <td>ffffec519fa37cf60c78</td>\n",
              "      <td>How can one start a research project based on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1306121</th>\n",
              "      <td>ffffed09fedb5088744a</td>\n",
              "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48170f87-d48b-4131-b458-4efba63010e9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48170f87-d48b-4131-b458-4efba63010e9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48170f87-d48b-4131-b458-4efba63010e9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                          qid  ... target\n",
              "1306102  ffff3778790af9baae76  ...      0\n",
              "1306103  ffff3f0a2449ffe4b9ff  ...      1\n",
              "1306104  ffff41393389d4206066  ...      0\n",
              "1306105  ffff42493fc203cd9532  ...      0\n",
              "1306106  ffff48dd47bee89fff79  ...      0\n",
              "1306107  ffff5fd051a032f32a39  ...      0\n",
              "1306108  ffff6d528040d3888b93  ...      0\n",
              "1306109  ffff8776cd30cdc8d7f8  ...      0\n",
              "1306110  ffff94d427ade3716cd1  ...      0\n",
              "1306111  ffffa382c58368071dc9  ...      0\n",
              "1306112  ffffa5b0fa76431c063f  ...      1\n",
              "1306113  ffffae5dbda3dc9e9771  ...      0\n",
              "1306114  ffffba7c4888798571c1  ...      0\n",
              "1306115  ffffc0c7158658a06fd9  ...      0\n",
              "1306116  ffffc404da586ac5a08f  ...      0\n",
              "1306117  ffffcc4e2331aaf1e41e  ...      0\n",
              "1306118  ffffd431801e5a2f4861  ...      0\n",
              "1306119  ffffd48fb36b63db010c  ...      0\n",
              "1306120  ffffec519fa37cf60c78  ...      0\n",
              "1306121  ffffed09fedb5088744a  ...      0\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.head(10)\n",
        "df.tail(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2optywC5mRQc",
        "outputId": "97f8c0e6-48ec-42ad-8252-e8e75e7d138c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting matplotlib==3.1.3\n",
            "  Using cached matplotlib-3.1.3-cp37-cp37m-manylinux1_x86_64.whl (13.1 MB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.3.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (1.21.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.1.3) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.1.3) (1.16.0)\n",
            "Installing collected packages: matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.5.1\n",
            "    Uninstalling matplotlib-3.5.1:\n",
            "      Successfully uninstalled matplotlib-3.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed matplotlib-3.1.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install matplotlib==3.1.3 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "leRFRWJMocVa",
        "outputId": "61a145ba-89a6-40fe-8736-1eccbd9692d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb69ec54650>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "\n",
        "df.target.plot(kind = 'hist', title = \"target Distribution\" )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAmAeFvpTpLE"
      },
      "source": [
        "Here we can see that there is a **class imbalace problem**. Majority of the data is good and only a small portion of the data is toxic. We will address this problem by using **stratified sampling** while we are creating our training and validation set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELjswHcFHfp3"
      },
      "source": [
        "## Task 4: Create tf.data.Datasets for Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fScULIGPwuWk",
        "outputId": "d8a76280-81d2-4678-fe48-e94d013e33f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9795, 3), (972, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_df, remaining = train_test_split(df, \n",
        "                                       random_state = 42,\n",
        "                                       train_size = 0.0075, # Since our dataset is huge we only take 0.75% of the whole data for training. ~10,000 samples only \n",
        "                                       stratify = df.target.values)\n",
        "\n",
        "valid_df, _ =   train_test_split(remaining, \n",
        "                                random_state = 42,\n",
        "                                train_size = 0.00075, # Since our dataset is huge we only take 0.075% of the whole data for validation. ~1,000 samples only \n",
        "                                stratify = remaining.target.values)\n",
        "train_df.shape, valid_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ioffBsJWawj"
      },
      "source": [
        "Criticisms and Drawbacks of BERT\n",
        "- Expensive to train \n",
        "- Slow at inference time \n",
        "\n",
        "Becacause of the following:\n",
        "- size of the model. \n",
        "- 109M+ parameters.  \n",
        "- I/O pipeline bottleneck (moving from CPU, RAM and GPU)\n",
        "\n",
        "To improve our model we need to make sure that we are super efficient during our preprocessing and dataloading phase. For this, we will be using tf.data API to reduce the time required to complete the steps. \n",
        "\n",
        "- Basically tf.data helps to build an efficient pipeline. This allows us to do all the preprocessing steps on the CPU, so that the GPU is available for the BERT model (No GPU overhead). The preprocessing will be done while the BERT is working so the preprocessed text is ready for the BERT model. \n",
        "- The preprocessing step is parallelized across multiple CPU cores as inputs are independent. Each input elemet needs to be preprocessed to generate:\n",
        "- - TokenIDs\n",
        "- - (generate) Input Mask IDs\n",
        "- - (generate) Input Type IDs\n",
        "\n",
        "\n",
        "This is made pussible by the argument in the td.data by defining how meny threads do you need in muli-processing. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBLG_5OZYZYt"
      },
      "source": [
        "To create a datapipeline, we need to start with the data scource. To construct a dataset from data in memory you can use the tf.data.tensors method or the tf.data.tensonslices method. The return object is Python itterable - so we could use that in a for loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQYMGT5_qLPX",
        "outputId": "90ebe986-73a9-4a8c-e011-d5baf3706f55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Why are unhealthy relationships so desirable?', shape=(), dtype=string)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "# this creates tf dataset for the training data \n",
        "with tf.device('/cpu:0'):\n",
        "  train_data = tf.data.Dataset.from_tensor_slices((train_df.question_text.values,\n",
        "                                                   train_df.target.values))\n",
        "  valid_data = tf.data.Dataset.from_tensor_slices((valid_df.question_text.values, \n",
        "                                                   valid_df.target.values))\n",
        "  \n",
        "# These dataset objects which will be returned using this function is a Python itterable, so we can consume its elements using a for loop. \n",
        "\n",
        "# Here, we are looking at the 1st element of the dataset. \n",
        "# Number of elements you want to look at are given by the argument of the take() function. take(1) will return 1 pair. \n",
        "  for text, label in train_data.take(1):\n",
        "    print(text)\n",
        "    print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4TEiqiIk1AM",
        "outputId": "580604f5-384e-4c54-8f7a-fbdb1051ec01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Why are unhealthy relationships so desirable?', shape=(), dtype=string)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(b'Which war changed the course of history of the world?', shape=(), dtype=string)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(b\"I have started a YouTube channel named AskHamy (link is given below). The problem is that I don't want to show myself and instead just want to do a voice-over. What are some things which I can show on screen so that the viewers don't get bored?\", shape=(), dtype=string)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "# Here, we are looking at the 1st element of the dataset. \n",
        "# Number of elements you want to look at are given by the argument of the take() function. take(1) will return 1 pair. \n",
        "for text, label in train_data.take(3):\n",
        "  print(text)\n",
        "  print(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2-ReN88Hvy_"
      },
      "source": [
        "## Task 5: Download a Pre-trained BERT Model from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMb5M86b4-BU"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Defining Hyper-parameters and some constants \n",
        "\n",
        "Each line of the dataset is composed of the review text and its label\n",
        "- Data preprocessing consists of transforming text to BERT input features:\n",
        "input_word_ids, input_mask, segment_ids\n",
        "- In the process, tokenizing the text is done with the provided BERT model tokenizer\n",
        "\"\"\"\n",
        "\n",
        "label_list = [0, 1] # Label categories - list of all labels\n",
        "# for multiclass BERT classifier - we could define 3 or more labels here\n",
        "# Other changes 1. the number of softmax units at the output of the model\n",
        "# Other changes 2. Loss function from binary cross entropy to sparce categorical cross entropy \n",
        "\n",
        "max_seq_length = 128 # maximum length of (token) input sequences - what is length of longest question that we will allow\n",
        "# BERT allows a max length of 512 tokens. \n",
        "\n",
        "train_batch_size = 32 \n",
        "\n",
        "# Get BERT layer and tokenizer:\n",
        "# More details here: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\",\n",
        "                            trainable = True) \n",
        "# As it is suggested that we train all the paramets of the model for any specific usage. by default it is false\n",
        "              \n",
        "# Instantiate the tokenizer - so that it taks care of all the preporcessing that is required. \n",
        "# load the vocab of the BERT model. It is about 30k words\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy() # explicit conversion from tensor to numpy\n",
        "\n",
        "# Now, we make sure that we are dealing with the uncased version of the Bert layer that we have imported. \n",
        "# Just checking this is not actual conversion of the text\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy() \n",
        "\n",
        "# Instantiate our tokenizer\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HoimWzBrj-w",
        "outputId": "51249f24-26fe-4d48-f6b5-7a9e4a2c1b89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "official.nlp.bert.tokenization.FullTokenizer"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "type(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEUezMK-zkkI",
        "outputId": "6e8f984f-0a6b-4c99-d409-8f9c32446248"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi',\n",
              " '##,',\n",
              " 'how',\n",
              " 'are',\n",
              " 'you',\n",
              " 'doing',\n",
              " '##?',\n",
              " '[UNK]',\n",
              " '[UNK]',\n",
              " 'went',\n",
              " 'playing',\n",
              " 'today',\n",
              " '##.']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "tokenizer.wordpiece_tokenizer.tokenize('hi, how are you doing? Hi, I went playing today.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note here than words with capital letters in them are identified as [UNK] as those words are not in the BERT vocab."
      ],
      "metadata": {
        "id": "SbUxutBnrpgZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbYty5M9zbdD",
        "outputId": "1aa86353-5e9c-453a-8a72-7fb6aee18c50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', '##,', 'how', 'are', 'you', 'doing', '##?']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tokenizer.wordpiece_tokenizer.tokenize('hi, how are you doing?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AFsmTO5JSmc",
        "outputId": "673e4193-82b0-4e58-daa0-b1b7326c1898"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7632, 29623, 2129, 2024, 2017, 2725, 29632]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Convert these token to Token IDs\n",
        "tokenizer.convert_tokens_to_ids(tokenizer.wordpiece_tokenizer.tokenize('hi, how are you doing?'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH4bKAE20mkS"
      },
      "source": [
        "Here, each word is represented as a token (or a number). - an index in the vocabulary \n",
        "\n",
        "Also, note that for each sentence we need to do padding - add a **CLS token** (at the start) and **SEP token** (at the end) tokens to represent a sequence. We will do this by the submodules that we have cloned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QinzNq6OsP1"
      },
      "source": [
        "## Task 6: Tokenize and Preprocess Text for BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FTqJ698zZ1e"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1-SpKFELnEvBMBqO7h3iypo8q9uUUo96P' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 2: BERT Tokenizer</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWYkggYe6HZc"
      },
      "source": [
        "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create InputExamples using `classifier_data_lib`'s constructor `InputExample` provided in the BERT library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-21A5aNJM0W"
      },
      "outputs": [],
      "source": [
        "# This provides a function to convert row to input features and label\n",
        "\n",
        "def to_feature(text, label, label_list=label_list, max_seq_length=max_seq_length, tokenizer=tokenizer):\n",
        "  \"\"\" This function is used to tokenize the text. (or it generates the features needed by the BERT) \n",
        "  convert the text and label ----to----> input features and label \n",
        "  \n",
        "  The inputs of the functions are:\n",
        "   1. text and label of a single row \n",
        "   2. constants \n",
        "   3. tokenizer - nlp bert tokenizer \n",
        "\n",
        "   This function then returns the following:\n",
        "   1. input_ids \n",
        "   2. input mask \n",
        "   3. input type ids (feature.label_id)\n",
        "   4. label\n",
        "\n",
        "   this generates the inputs needed for the BERT model \n",
        "   \"\"\"\n",
        "\n",
        "  #define input example\n",
        "  example = classifier_data_lib.InputExample(guid=None, \n",
        "                                             text_a = text.numpy, # the text we want to classify. Also, convert it from tensor format to numpy format\n",
        "                                             text_b = None, # We would use this argument in NSP - Next Sentence Prediction\n",
        "                                             label = label.numpy())\n",
        "  \n",
        "  #Convert the exaple into features by using the constructor function\n",
        "  feature = classifier_data_lib.convert_single_example(0, # index of the 0th example. since the length of exaple is only 1 \n",
        "                                                       example, \n",
        "                                                       label_list, #In this case [0, 1]\n",
        "                                                       max_seq_length, # in this case it is 128 \n",
        "                                                       tokenizer) # also, pass our tokenizer for index values\n",
        "\n",
        "  return(feature.input_ids, feature.input_mask, feature.segment_ids, feature.label_id)\n",
        "\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpYDxtDLs8JR"
      },
      "source": [
        "**Why do we need the Input Mask?**\n",
        "\n",
        "In our BERT model, we have defined the max_seq_length as 128. Meaning that all input sequences (or sentences) should be of 128 (as BERT takes sequences of equal lengths only). The sequences which are short will be padded. Also, these sequences will be padded with [CLS] - start token and [SEP] - end token. \n",
        "\n",
        "The problem with adding paddings is that we are adding elements which are not adding any meaning to the sequence. So, we use the input mask to take care of these padding words. Then the BERT model will not pay attention to these padding words. \n",
        "\n",
        "How it works: \n",
        "\n",
        "text = [\"Hello how are you\"]\n",
        "\n",
        "tokens = [[CLS], \"hello\", \"how\", \"are\", \"you\", [SEP]]\n",
        "\n",
        "token_ids = [14, 56, 26, 7888, 1090, 30229]\n",
        "\n",
        "input_mask = [0, 1,    1,   1,   1,     0]\n",
        "\n",
        "So, the dot product of token_ids and input_mask will remove any padding words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXo9dx0cvlKW"
      },
      "source": [
        "**Input Type ID** \n",
        "\n",
        "BERT was pretarained on two tasks:\n",
        "- Masked language modelling - task to predict what are masked tokens are  \n",
        "- NSP - next sentence prediction \n",
        "\n",
        "Since, in our example we are not dealing with Next sentence prediction, so do not use Input Type ID.\n",
        "\n",
        "*text_b = None*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atfbDGFsy6xw"
      },
      "source": [
        "**What's Next... Caveat?**\n",
        "\n",
        "We cannot directly use the function to_feature() directly to create our input datastructures (or feature datastructures). \n",
        "\n",
        "We want to use dt.dataset.map() to apply the function to each element of the input dataset. But dataset.map() runs in graph mode. \n",
        "\n",
        "This is the problem, as graph tensors do not have a value and in graph mode you can use only tensorflow ops and functions. So, basically you cannot map the function directly to our data. We need to wrap it in a tensorflow Python function class --- this will create a wrapper function \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_HQSsHwWCsK"
      },
      "source": [
        "You want to use [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) to apply this function to each element of the dataset. [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) runs in graph mode.\n",
        "\n",
        "- Graph tensors do not have a value.\n",
        "- In graph mode you can only use TensorFlow Ops and functions.\n",
        "\n",
        "So you can't `.map` this function directly: You need to wrap it in a [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function). The [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function) will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaNlkKVfWX0Q"
      },
      "source": [
        "## Task 7: Wrap a Python Function into a TensorFlow op for Eager Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCPpQFzc_qNB",
        "outputId": "2487ee4f-a43b-45ff-c66b-80ee2d1ee6f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "max_seq_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGACBcfCWC2O"
      },
      "outputs": [],
      "source": [
        "def to_feature_map(text, label):\n",
        "  \"\"\" Thhis function is a wrapper function for ti_feature function \n",
        "  essentially, instead of graph function (which has no values) this \n",
        "  function will pass regular tensors (which have values)\"\"\"\n",
        "\n",
        "  # this is the wrapper \n",
        "  input_ids, input_mask, segment_ids, label_id = tf.py_function(to_feature, # name of the function we are wrapping \n",
        "                                                                inp = [text, label], # input of the function is going to be text and label\n",
        "                                                                Tout = [tf.int32, tf.int32, tf.int32, tf.int32]) # define the output type of the function - Tensor integers\n",
        "  \n",
        "  # set the shape fo all these tensors as the wrapper does not do that\n",
        "  input_ids.set_shape([max_seq_length])\n",
        "  input_mask.set_shape([max_seq_length])\n",
        "  segment_ids.set_shape([max_seq_length])\n",
        "  label_id.set_shape([])\n",
        "\n",
        "  # Bundle all the input variables in a dictionary - single variable\n",
        "  x = {'input_word_ids': input_ids,\n",
        "       'input_mask': input_mask,\n",
        "       'input_type_ids': segment_ids}\n",
        "\n",
        "  return(x, label_id)\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhdO6MjTbtn1"
      },
      "source": [
        "## Task 8: Create a TensorFlow Input Pipeline with `tf.data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHRdiO3dnPNr"
      },
      "outputs": [],
      "source": [
        "\n",
        "with tf.device('/cpu:0'):\n",
        "  # # train\n",
        "  train_data = (train_data.map(to_feature_map, \n",
        "                               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  .shuffle(1000)\n",
        "  .batch(32, drop_remainder = True)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "\n",
        "  # valid\n",
        "  valid_data = (valid_data.map(to_feature_map, #calling the wrapper function \n",
        "                                num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
        "  .batch(32, drop_remainder = True)\n",
        "  .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "  #Tensorflow input pipeline is now created\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLUWnfx-YDi2"
      },
      "source": [
        "The resulting `tf.data.Datasets` return `(features, labels)` pairs, as expected by [`keras.Model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0Z2cy9GHQ8x",
        "outputId": "37a7ee97-be17-409a-fd83-d5e3870760d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_mask': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_type_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_word_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None)},\n",
              " TensorSpec(shape=(32,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# train data spec\n",
        "train_data.element_spec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGAH-ycYOmao",
        "outputId": "9e1de8f6-0d9f-47b1-8f79-35fe5ba4f42b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_mask': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_type_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_word_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None)},\n",
              " TensorSpec(shape=(32,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# valid data spec\n",
        "valid_data.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZxe-7yhPyQe"
      },
      "source": [
        "## Task 9: Add a Classification Head to the BERT Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9THH5V0Dw2HO"
      },
      "source": [
        "<div align=\"center\">\n",
        "    <img width=\"512px\" src='https://drive.google.com/uc?id=1fnJTeJs5HUpz7nix-F9E6EZdgUflqyEu' />\n",
        "    <p style=\"text-align: center;color:gray\">Figure 3: BERT Layer</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ref Test -> https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\n",
        "\n",
        "\n",
        "*pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])*\n",
        "\n",
        "There are two outputs: a pooled_output of shape [batch_size, 768] with representations for the entire input sequences and a sequence_output of shape [batch_size, max_seq_length, 768] with representations for each input token (in context).\n",
        "\n",
        "Sentence_output - This talks about the context in reference which is a representation of all input tokens. \n",
        "\n",
        "pooled_output roughly corresponds to the hidden state corresponding to the CLS classification token from the BERT paper. We can then pass the pooled_output through a softmax function to get the probabilities. "
      ],
      "metadata": {
        "id": "AhV6nGu0vDGE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9il4gtlADcp"
      },
      "outputs": [],
      "source": [
        "# Building the model\n",
        "def create_model():\n",
        "  # Ref (under usage) ->-> https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "  input_type_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"input_type_ids\")\n",
        "  \n",
        "  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
        "\n",
        "  # Now we have the pooled output and the sequence output\n",
        "\n",
        "  # here we could add a couple of dense layers but we are going to skip that for the sake of simplicity\n",
        "\n",
        "  #Now we are going to add a few dropout layers to prevent overfitting on the training data\n",
        "  # 0.4 is a very high dropout layer in general - we can experimet with this later on\n",
        "  drop = tf.keras.layers.Dropout(0.4)(pooled_output)\n",
        "  #now get the final classification output - this is going to be a dense layer\n",
        "  output = tf.keras.layers.Dense(1, \n",
        "                          activation='sigmoid', # for binary classification we use sigmoid this converts values between -1 and 1 to 0 and 1\n",
        "                          name = \"output\")(drop)\n",
        "\n",
        "  model = tf.keras.Model(\n",
        "      inputs = {'input_word_ids': input_word_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'input_type_ids': input_type_ids},\n",
        "      outputs = output)\n",
        "  \n",
        "  return model\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6maM-vr7YaJ"
      },
      "source": [
        "## Task 10: Fine-Tune BERT for Text Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptCtiiONsBgo",
        "outputId": "a3a7e7c7-96a2-40c9-b46b-559e37131393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_mask (InputLayer)         [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
            "                                                                 input_mask[0][0]                 \n",
            "                                                                 input_type_ids[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 768)          0           keras_layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "output (Dense)                  (None, 1)            769         dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 109,483,010\n",
            "Trainable params: 109,483,009\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_model()\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "6GJaFnkbMtPL",
        "outputId": "06a43b52-c811-4d1a-ccc9-12d240064506"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "tf.keras.utils.plot_model(model=model,\n",
        "                          show_shapes=True,\n",
        "                          dpi = 76) # by default it is 96"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbD7DEqY8nfQ",
        "outputId": "1f92968e-f6b3-47bd-cad2-53034278a430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OcREcgPUHr9O",
        "outputId": "504062e4-f289-46f1-ceda-d12cb7e63174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-fe666c14cc47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     verbose = 1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument:  ValueError: Unsupported string type: <class 'method'>\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 242, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 131, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-20-7ffbd31524be>\", line 32, in to_feature\n    tokenizer) # also, pass our tokenizer for index values\n\n  File \"models/official/nlp/data/classifier_data_lib.py\", line 847, in convert_single_example\n    tokens_a = tokenizer.tokenize(example.text_a)\n\n  File \"models/official/nlp/bert/tokenization.py\", line 183, in tokenize\n    for token in self.basic_tokenizer.tokenize(text):\n\n  File \"models/official/nlp/bert/tokenization.py\", line 213, in tokenize\n    text = convert_to_unicode(text)\n\n  File \"models/official/nlp/bert/tokenization.py\", line 96, in convert_to_unicode\n    raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n\nValueError: Unsupported string type: <class 'method'>\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) Invalid argument:  ValueError: Unsupported string type: <class 'method'>\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 242, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 131, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 302, in wrapper\n    return func(*args, **kwargs)\n\n  File \"<ipython-input-20-7ffbd31524be>\", line 32, in to_feature\n    tokenizer) # also, pass our tokenizer for index values\n\n  File \"models/official/nlp/data/classifier_data_lib.py\", line 847, in convert_single_example\n    tokens_a = tokenizer.tokenize(example.text_a)\n\n  File \"models/official/nlp/bert/tokenization.py\", line 183, in tokenize\n    for token in self.basic_tokenizer.tokenize(text):\n\n  File \"models/official/nlp/bert/tokenization.py\", line 213, in tokenize\n    text = convert_to_unicode(text)\n\n  File \"models/official/nlp/bert/tokenization.py\", line 96, in convert_to_unicode\n    raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n\nValueError: Unsupported string type: <class 'method'>\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_42438]\n\nFunction call stack:\ntrain_function -> train_function\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "epochs = 3\n",
        "history = model.fit(train_data,\n",
        "                    validation_data = valid_data, \n",
        "                    epochs = epochs, \n",
        "                    verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This should take about 8- 10 mins to complete. \n",
        "\n",
        "We are looking for an accuracy of >0.93 and loss of < 1.8 "
      ],
      "metadata": {
        "id": "PbSTIWZ05pqn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNZl1lx_cA5Y"
      },
      "source": [
        "## Task 11: Evaluate the BERT Text Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCjgrUYH_IsE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6lrFRra_KmA"
      },
      "outputs": [],
      "source": [
        "plot_graphs(history, 'loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opu9neBA_98R"
      },
      "outputs": [],
      "source": [
        "plot_graphs(history, 'binary_accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkhtCCgnUbY6"
      },
      "outputs": [],
      "source": [
        "sample_example = [\"sentence 1\", \"2\"] # keep it less than 32\n",
        "test_data = tf.data.Dataset.from_tensor_slices((sample_example, [0]*len(sample_example)))\n",
        "test_data = (test_data.map(to_feature_map).batch(1))\n",
        "preds = model.predict(test_data)\n",
        "threshold = 0.5 #between 0 and 1\n",
        "[\"Insincere\" if pred >= threshold else \"Sincere\" for pred in preds]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4B8NQBLd9rN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeVNOGfFJT9O"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_YWudFRJT__"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hENB__IlJUCk"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkYpiGrhJUFK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYqbQZJnJUHw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aiKuBGgfJUKv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Copy of Fine-Tune-BERT-for-Text-Classification-with-TensorFlow.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}